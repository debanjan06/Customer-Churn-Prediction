
version: '3.8'

services:
  churn-prediction-api:
    build: .
    container_name: churn_prediction_api
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
    volumes:
      - ./models:/app/models:ro
    restart: unless-stopped
    depends_on:
      - mlflow

  mlflow:
    image: python:3.10-slim
    container_name: mlflow_server
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow:/mlflow
    working_dir: /mlflow
    command: >
      bash -c "
        pip install mlflow &&
        mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri file:///mlflow --default-artifact-root file:///mlflow/artifacts
      "
    restart: unless-stopped

networks:
  default:
    name: churn_prediction_network
